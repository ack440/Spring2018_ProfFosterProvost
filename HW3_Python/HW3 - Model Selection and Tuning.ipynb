{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Name: _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "## Model Selection and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise should guide you through performing a predictive modeling analysis.  You will choose a model type, set critical complexity parameters, and apply it to select prospects for a direct mailing charity campaign.  If you get stuck, please ask questions on the discussion forum – it’s likely that other students are running into the same issues!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mailing marketing offers can be costly.  We want to send out solicitations for donations; each solicitation costs us a small amount.  Under NYU Classes->Resources->Data->Homework 3 Mailing you will find two data files from our problem.  The files are mailing_test.arff and mailing_train.arff. \n",
    "\n",
    "You can also find these two files in this repository's \"data\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will analyze (at least) three algorithms for these data: tree induction, logistic regression, and any other method of your choice.  Your ultimate goal is to build the ‘best’ model given the data and to do some analytics on the model.  You have a budget of $3000, and you will decide how to spend that on targeting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set if `TARGET_B = 1` the person donated, otherwise, they did not donate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Load and/or install the following packages:\n",
    "- `liac-arff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:"
     ]
    }
   ],
   "source": [
    "# for example\n",
    "! sudo pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mailing_train.arff.\n",
    "(see documentation [here](https://pypi.python.org/pypi/liac-arff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mailing_data_train = arff.load(open('data/mailing_train.arff'))\n",
    "mailing_data_test = arff.load(open('data/mailing_test.arff'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a pandas dataframe and use \"head\" to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(mailing_data_train['data'])\n",
    "test_df = pd.DataFrame(mailing_data_test['data'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the columns their proper names\n",
    "a = mailing_data_train['attributes']\n",
    "train_df.columns = [i[0] for i in a] \n",
    "test_df.columns = [i[0] for i in a] \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "There seem to be many missing values (NaN). We will use the built-in feature [.dropna()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) in Pandas to drop any rows with missing values. Dropping NA's is not necessarily the best thing to do in practice, but that is a topic for another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no_nas = train_df.dropna()\n",
    "test_df_no_nas = test_df.dropna()\n",
    "\n",
    "print(\"original number of rows: \\t\" + str(train_df.shape[0]))\n",
    "print(\"New number of rows: \\t \\t\" + str(train_df_no_nas.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to throw away a lot of data, let's drop columns with Na's instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_no_nas = train_df.dropna(axis=1)\n",
    "\n",
    "# # make sure the test data has the same columns\n",
    "# test_df_no_nas = test_df[np.array(train_df_no_nas.columns)]\n",
    "\n",
    "# print(\"original number of cols: \\t\" + str(train_df.shape[1]))\n",
    "# print(\"New number of cols: \\t \\t\" + str(train_df_no_nas.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have a fixed budget, you’ll be ranking the instances based on their predicted probability of donation.  This will maximize the expected number of donations for the $3000 budget.  Therefore, be sure to compare the “ROC Area” measure that we discussed in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK Learn's algorithms cannot easily handle categorical data, so convert each categorical feature into a series of binary \"dummy\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df_no_nas.loc[:, train_df_no_nas.columns != 'TARGET_B']\n",
    "Y = train_df_no_nas[\"TARGET_B\"]\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Model\n",
    "Build the best model you can by changing the complexity paraemters for each of the following three model types, in terms of their generalization performance using ROC Area (you can use a 66% train/test split for this to save time):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trees\n",
    "Look at the documentation for decision tree classifies [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and decide which complexity parameter to tune - min_samples_split, or min_samples_leaf.\n",
    "\n",
    "Display a table showing the AUC over a range of your chosen complexity parameter.\n",
    "\n",
    "I have done it for max_depth already. **Choose a different complexity parameter to use to find the best validation performance of the tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score # for AUC scores\n",
    "\n",
    "\n",
    "# for example, using max_depth\n",
    "complexity_param = \"max_depth\"\n",
    "\n",
    "# create an empty list to hold the cross validation scores\n",
    "accuracies_cross_validation = []\n",
    "\n",
    "# Model\n",
    "#number of folds for cross validation\n",
    "n_folds = 3\n",
    "\n",
    "param_range = range(1,10)\n",
    "for param in param_range:\n",
    "    model_Tree = DecisionTreeClassifier(max_depth = param) ### BE SURE TO CHANGE THIS!\n",
    "    AUC = np.mean(cross_val_score(model_Tree, X, Y,cv=n_folds))\n",
    "    accuracies_cross_validation.append(AUC)\n",
    "    #print(complexity_param + \" = \" + str(param) + \", AUC = \" + str(AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide Charts and graphs to support your choice of complexity parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary with curly brackest {}\n",
    "d = {complexity_param :[i for i in param_range], \"AUC\" : accuracies_cross_validation} \n",
    "# Convert the dict into a data frame\n",
    "df = pd.DataFrame(d, columns =[complexity_param,'AUC'] )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "df.loc[(df.iloc[:,1] == max(df.iloc[:,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#df.plot.line(df.columns[0],df.columns[1])\n",
    "\n",
    "plt.scatter(df.iloc[:,0],df.iloc[:,1])\n",
    "plt.plot(df.iloc[:,0],df.iloc[:,1])\n",
    "plt.xlabel(complexity_param)\n",
    "plt.ylabel('AUC')\n",
    "plt.title(\"Decision Tree Classifier\\n AUC vs. \"+ complexity_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose the model with the following complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Look at the documentation for logistic regression classifiers [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "Display a table showing the AUC over a range of your chosen penalty parameter (`\"l1`\" or `\"l2\"`). Change the argument \"C\" by exponential values of 10 to find the best cross-validated AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Choice!\n",
    "A third model type of your choice.  Some model types won’t have a complexity parameter to tune, so just run them with the default settings.  Some suggestions: [Naïve Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) (see Chapter 9; no complexity parameter), [kNN classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) – see Chapter 6. increase parameter `n_neighbors` to make a simpler model, [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) - an ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Model to Choose\n",
    "Tell us the process you went through to set the complexity parameter for each model, ideally providing appropriate charts or graphs to support your decision (note: you don’t need to give us the full fitting curves, but do provide convincing evidence as to why you chose the parameter setting you did). \n",
    "#### Your answer here!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pick one model to move forward with.  Why did you select this one?\n",
    "#### Your answer here!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a Threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data using train_test_split to estimate the model's performance on unseen data. Store predictions as probability scores of being class `1` using `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,train_size=.67,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## As a demonstration I test it on a basic out-of-the-box logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Do it with your model here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the estimated probabilities to rank the prospects for propensity to donate if targeted with a mailing. Hint: use [DataFrame.sort_values()](http://pandas.pydata.org/pandas-docs/version/0.18/generated/pandas.DataFrame.sort.html). Print the top 10 rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'predicted_prob_donate' : probabilities[:,1], # we only select the probability of class = 1 (i.e. the second column)\n",
    "     'actually_donated' : Y_test}\n",
    "df = pd.DataFrame(d)\n",
    "df_sorted = df.sort_values(\"predicted_prob_donate\",ascending=False)\n",
    "\n",
    "# your work here. print the top 10 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many people can you target?\n",
    "The cost of each mailing is \\$2 and the budget is $3000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You work here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Lift?\n",
    "Compute the lift you would (expect to) achieve if you target the top 1%, 5%, and 10% of the people in the test set by your ranking. What percent of the entire population would donate (if chosen at random)?  How do these compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You work here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code used to construct a lift curve (lift vs. percent targeted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift = {'pct' : [], 'lift' : []}\n",
    "for i in range(1,100):\n",
    "    top_n_pct = float(i)/100 # percent\n",
    "    top_n_rows = int(df_sorted.shape[0]*top_n_pct)\n",
    "\n",
    "    # number of \"true positives\" in the top n%\n",
    "    TP = sum(pd.to_numeric(df_sorted.iloc[1:top_n_rows,0]))\n",
    "    pct_TP = np.mean(pd.to_numeric(df_sorted.iloc[1:top_n_rows,0]))\n",
    "\n",
    "    # base rate\n",
    "    base_rate = np.mean(pd.to_numeric(df[\"actually_donated\"]))\n",
    "\n",
    "    # lift\n",
    "    lift['lift'].append(pct_TP / base_rate)\n",
    "    lift['pct'].append(top_n_pct)\n",
    "    \n",
    "lift_df = pd.DataFrame(lift)\n",
    "\n",
    "plt.scatter(lift_df['pct'],lift_df['lift'])\n",
    "plt.plot(lift_df['pct'],lift_df['lift'])\n",
    "plt.xlabel('fraction of people targeted')\n",
    "plt.ylabel('lift')\n",
    "plt.title('Lift Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You work here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Benefit Analysis\n",
    "Assume that each donation is \\$10 and the cost of each mailer is \\$2.\n",
    "\n",
    "Compute the (expected) profit for each of the three thresholds (1%, 5%, 10%) of the population.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a cumulative profit curve (profit vs. percent targeted) and show it below. You can reuse code from the Lift Curve above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your work here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct another profit curve, instead using the probability \"cutoff treshold\" as your X-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your work here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing Profit\n",
    "What threshold should you use if you are trying to maximize your total expected profit?  What would the total profit be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Even\n",
    "What threshold should you use if you want to send the most mailings you can and still “break even”?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment: Which People to Target?\n",
    "The above analyses were run purely using different splits of the training data. Now assume we have a new set of people to target, held in the file `mailing_test.arff`.\n",
    "\n",
    "Given the decisions you made above, let's make some choices about the people in this \"deployment\" dataset.\n",
    "\n",
    "I have provided the code below for you to merge the train and the test sets to ensure they both have the same column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# First, let us make sure that the test set and training set have the same columns\n",
    "both= pd.concat([train_df_no_nas,test_df_no_nas],axis=0)\n",
    "both.dropna(axis=1)\n",
    "X = both.iloc[:,both.columns != 'TARGET_B']\n",
    "\n",
    "# remember to get the dummy variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# the target is entered as a string, let's convert it to numeric\n",
    "Y = pd.to_numeric(both['TARGET_B'])\n",
    "\n",
    "train_size = train_df_no_nas.shape[0] # the number of rows in the training set\n",
    "X_train, X_deploy, Y_train, Y_deploy = train_test_split(X, Y, train_size=train_size,shuffle=False) # turn shuffle off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the estimated probabilities to rank the prospects for propensity to donate if targeted with a mailing **on the deployment data (X_deploy)**.\n",
    "\n",
    "In this deployment stage, pretend you cannot see the true labels (Y_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here. print the top 10 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing Profit\n",
    "Using our threshold chosen above, how many people in the deployment set should we target? What is the estimated total profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Even\n",
    "How many people in the deployment set can we target if we just want to “break even”?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about the budget\n",
    "What is your expected profit for your $3000 budget?  Does this budget make business sense for these data?  Make a recommendation for what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing Past Decisions\n",
    "Pretend you are now in the future, and have the true labels for the people whom you sent the mailer to (Y_deploy). Compute your actual profit using the chosen threshold and compare to your estimated profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Ungraded)  Calculate the actual lift \n",
    "How do you calculate the base rate, given you do not (ostensibly) have the \"actual\" labels for people you do not give the mailers to?\n",
    "\n",
    "Compute your actual lift using the chosen threshold and compare to your estimated lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your explanation here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in Assignment\n",
    "Save this notebook as a pdf using\n",
    "\n",
    "`File>Download as>PDF via LaTeX (.pdf)` \n",
    "\n",
    "submit as PDF on NYU classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
